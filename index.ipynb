{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson processes for fun and profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nelson Uhan<br>\n",
    "October 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A really important question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Taylor Swift's tweets follow a Poisson process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we determine if an arrival process is Poisson?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach: __look at the interarrival times__.\n",
    "\n",
    "* Are the interarrival times exponentially distributed?\n",
    "* Are the interarrival times independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a [Jupyter Notebook](http://www.jupyter.org), which lets you mix live code, equations, text, and images into one interactive document. \n",
    "\n",
    "The code in this notebook is written in the [Python](http://www.python.org) programming language.\n",
    "\n",
    "To execute a code cell:\n",
    "\n",
    "1. Click inside a code cell\n",
    "2. Either\n",
    "    * press <key><i class=\"fa fa-step-forward\" aria-hidden=\"true\"></i></key> in the toolbar, or\n",
    "    * press Shift + Enter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import a whole bunch of libraries, including [Tweepy](http://www.tweepy.org), which allows us to interface with Twitter programmatically using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Import libraries\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to authenticate into Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate into Twitter\n",
    "consumer_key = 'CONSUMER_KEY'\n",
    "consumer_secret = 'CONSUMER_SECRET'\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting someone's tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab some information about the Twitter user we want to study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter Twitter user name\n",
    "username = 'taylorswift13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about this Twitter user\n",
    "user = api.get_user(username)\n",
    "print(f'Name: {user.name}')\n",
    "IPython.display.Image(user.profile_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab this user's last 200 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user's last 200 tweets\n",
    "public_tweets = []\n",
    "for tweet in tweepy.Cursor(api.user_timeline, screen_name=username).items(200):\n",
    "    public_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure we're doing this right &mdash; let's examine this user's last 10 tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print user's last 10 tweets: date/time, text\n",
    "for tweet in public_tweets[:10]:\n",
    "    print(\"{0} {1}\".format(tweet.created_at, tweet.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing interarrival times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, looks good! Now let's create a list of just the tweet arrival times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just the arrival times\n",
    "arrival_times = []\n",
    "for tweet in public_tweets:\n",
    "    arrival_times.append(tweet.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can compute the interarrival times by\n",
    "\n",
    "* sorting the arrival times, and then \n",
    "* computing the difference in consecutive arrival times.\n",
    "\n",
    "The times are in seconds, so we divide the interarrival times by $60 \\times 60$ to obtain times in hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort arrival times\n",
    "arrival_times.sort()\n",
    "\n",
    "# Compute interarrival times in hours\n",
    "interarrival_times = []\n",
    "for a, b in zip(arrival_times, arrival_times[1:]):\n",
    "    interarrival_times.append((b - a).seconds / (60 * 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another sanity check: do the interarrival times look reasonable? Let's print out the first 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(interarrival_times[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see if the interarrival times fit an exponential distribution. \n",
    "\n",
    "Recall that the exponential distribution has a parameter, the arrival rate $\\lambda$. \n",
    "\n",
    "What should we use for $\\lambda$?\n",
    "\n",
    "It turns out that the maximum likelihood estimator is\n",
    "\n",
    "$$\n",
    "\\hat{\\lambda} = \\frac{1}{\\text{sample mean of the observed interarrival times}}\n",
    "$$\n",
    "\n",
    "Let's compute this next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample mean of the interarrival times\n",
    "interarrival_time_SM = np.mean(interarrival_times)\n",
    "print(f'Sample mean of interarrival times: {interarrival_time_SM} hours per tweet')\n",
    "\n",
    "# Estimated arrival rate (maximum likelihood)\n",
    "estimated_arrival_rate = 1 / interarrival_time_SM\n",
    "print(f'Estimated arrival rate: {estimated_arrival_rate} tweets per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the histogram of interarrival times with the pdf of the exponential distribution with the estimated arrival rate $\\hat{\\lambda}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pdf data points\n",
    "x_max = max(interarrival_times)\n",
    "x_values = np.arange(0, x_max, x_max / 1000)\n",
    "pdf_values = [stats.expon.pdf(x, scale=1 / estimated_arrival_rate) for x in x_values]\n",
    "\n",
    "# Create histogram with pdf of fitted exponential distribution\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.hist(interarrival_times, density=True)\n",
    "ax.plot(x_values, pdf_values);\n",
    "ax.set_xlim(0, max(interarrival_times));\n",
    "ax.set_xlabel('Interarrival time');\n",
    "ax.set_ylabel('Frequency');\n",
    "ax.set_title('Histogram of interarrival times and pdf of fitted exponential distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What do you think?__\n",
    "\n",
    "__Do you think the interarrival times are from an exponential distribution?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would perform some goodness-of-fit tests to statistically determine whether the exponential distribution is a good fit for the interarrival times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to check independence of the interarrival times. One easy visual test is to plot the interarrival times as a time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interarrival times as time series\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(interarrival_times);\n",
    "ax.set_xlabel('First to last');\n",
    "ax.set_ylabel('Interarrival time');\n",
    "ax.set_title('Interarrival times');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What do you think?__\n",
    "\n",
    "__Are the interarrival times independent?__\n",
    "\n",
    "__What type of user would you expect to tweet according to a Poisson process?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #poisson?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the same thing with hashtags. Let's grab the last 200 tweets with a certain hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter hashtag to search\n",
    "search_text = \"#dank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last 200 tweets with this hashtag\n",
    "cursor = tweepy.Cursor(api.search, q=search_text)\n",
    "hashtag_tweets = []\n",
    "for tweet in cursor.items(200):\n",
    "    hashtag_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print last 10 tweets with this hashtag: date/time, text\n",
    "for tweet in hashtag_tweets[:10]:\n",
    "    print(\"{0} {1}\".format(tweet.created_at, tweet.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can go through the same process as we did above.\n",
    "\n",
    "Since hashtags appear more frequently than one user's tweets, let's change the time scale to minutes instead of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just the arrival times\n",
    "ht_arrival_times = []\n",
    "for tweet in hashtag_tweets:\n",
    "    ht_arrival_times.append(tweet.created_at)\n",
    "\n",
    "# Sort arrival times\n",
    "ht_arrival_times.sort()\n",
    "\n",
    "# Compute interarrival times in minutes\n",
    "ht_interarrival_times = []\n",
    "for a, b in zip(ht_arrival_times, ht_arrival_times[1:]):\n",
    "    ht_interarrival_times.append((b - a).seconds / 60)\n",
    "    \n",
    "# Sample mean of the interarrival times\n",
    "ht_interarrival_time_SM = np.mean(ht_interarrival_times)\n",
    "print(\"Sample mean of interarrival times: {0} minutes per tweet\".format(ht_interarrival_time_SM))\n",
    "\n",
    "# Estimated arrival rate (maximum likelihood)\n",
    "ht_estimated_arrival_rate = 1 / ht_interarrival_time_SM\n",
    "print(\"Estimated arrival rate: {0} tweets per minute\".format(ht_estimated_arrival_rate))\n",
    "\n",
    "# Create pdf data points\n",
    "x_max = max(ht_interarrival_times)\n",
    "x_values = np.arange(0, x_max, x_max / 1000)\n",
    "pdf_values = [stats.expon.pdf(x, scale=1 / ht_estimated_arrival_rate) for x in x_values]\n",
    "\n",
    "# Create histogram with pdf of fitted exponential distribution\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.hist(ht_interarrival_times, density=True)\n",
    "ax.plot(x_values, pdf_values);\n",
    "ax.set_xlim(0, max(ht_interarrival_times));\n",
    "ax.set_xlabel('Interarrival time');\n",
    "ax.set_ylabel('Frequency');\n",
    "ax.set_title('Histogram of interarrival times and pdf of fitted exponential distribution');\n",
    "\n",
    "# Plot interarrival times as time series\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(ht_interarrival_times);\n",
    "ax.set_xlabel('First to last');\n",
    "ax.set_ylabel('Interarrival time');\n",
    "ax.set_title('Interarrival times');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What do you think?__\n",
    "\n",
    "__Are the interarrival times from an exponential distribution?__\n",
    "\n",
    "__Are the interarrival times independent?__\n",
    "\n",
    "__What type of hashtag would you expect to follow a Poisson process?__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
